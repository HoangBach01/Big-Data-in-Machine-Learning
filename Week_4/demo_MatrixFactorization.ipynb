{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    '''\n",
    "    R: rating matrix\n",
    "    P: |U| * K (User features matrix)\n",
    "    Q: K * |I| (Item features matrix)\n",
    "    K: latent features\n",
    "    steps: iterations\n",
    "    alpha: learning rate\n",
    "    beta: regularization parameter'''    \n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    # calculate error between Rij and R_hat_ij\n",
    "                    eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "\n",
    "                    for k in range(K):\n",
    "                        # calculate gradient with alpha and beta parameter\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "\n",
    "        eR = np.dot(P,Q) # R hat\n",
    "\n",
    "        e = 0 # error\n",
    "\n",
    "        for i in range(len(R)):\n",
    "\n",
    "            for j in range(len(R[i])):\n",
    "\n",
    "                if R[i][j] > 0:\n",
    "\n",
    "                    e = e + pow(R[i][j] - np.dot(P[i,:],Q[:,j]), 2)\n",
    "\n",
    "                    for k in range(K):\n",
    "\n",
    "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "        # 0.001: local minimum\n",
    "        if e < 0.001:\n",
    "\n",
    "            break\n",
    "\n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.43170473, 4.47961846, 2.0072065 , 1.85613828],\n",
       "       [3.98880305, 4.884435  , 3.49082882, 1.78689104],\n",
       "       [3.90864445, 4.98881825, 2.6933289 , 1.98378502],\n",
       "       [3.13268627, 3.49279457, 3.97440568, 1.00878281]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = [\n",
    "     [0, 4.5, 2.0, 0],\n",
    "     [4, 0, 3.5, 0],\n",
    "     [0, 5, 0, 2], \n",
    "     [0, 3.5, 4.0, 1.0]\n",
    "    ]\n",
    "\n",
    "R = np.array(R)\n",
    "# N: num of User\n",
    "N = len(R)\n",
    "# M: num of Movie\n",
    "M = len(R[0])\n",
    "# Num of Features\n",
    "K = 2\n",
    "\n",
    " \n",
    "P = np.random.rand(N,K)\n",
    "Q = np.random.rand(K,M)\n",
    "\n",
    "\n",
    "nP, nQ = matrix_factorization(R, P, Q, K, steps=10000)\n",
    "\n",
    "nR = np.dot(nP, nQ)\n",
    "\n",
    "nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.75762048, 0.40737575],\n",
       "       [1.59057038, 1.2207838 ],\n",
       "       [1.84280482, 0.72679066],\n",
       "       [0.76748654, 1.754475  ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.71222712, 2.32276883, 0.68657009, 1.02690275],\n",
       "       [1.03653515, 0.97470797, 1.96495954, 0.12576342]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.89577339, 5.00693605, 1.04370594, 2.9852719 ],\n",
       "       [3.85663695, 7.14615882, 5.94906312, 1.05272356],\n",
       "       [1.81516337, 3.96334912, 2.04486983, 1.4863513 ],\n",
       "       [2.06287214, 4.02899064, 2.92206358, 0.90429915],\n",
       "       [1.41575831, 2.87134095, 1.87172306, 0.79607133]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = [\n",
    "     [2, 5, 1, 3],\n",
    "     [4, 0, 0, 1],\n",
    "     [0, 4, 2, 0], \n",
    "     [2, 4, 3, 1],\n",
    "     [1, 3, 2, 0]\n",
    "    ]\n",
    "\n",
    "R = np.array(R)\n",
    "# N: num of User\n",
    "N = len(R)\n",
    "# M: num of Movie\n",
    "M = len(R[0])\n",
    "# Num of Features\n",
    "K = 2\n",
    "\n",
    " \n",
    "P = np.random.rand(N,K)\n",
    "Q = np.random.rand(K,M)\n",
    "\n",
    "\n",
    "nP, nQ = matrix_factorization(R, P, Q, K, steps=10000)\n",
    "\n",
    "nR = np.dot(nP, nQ)\n",
    "\n",
    "nR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1110812 , 0.53127409],\n",
       "       [0.59442564, 2.74764472],\n",
       "       [1.01009678, 0.96421265],\n",
       "       [0.56943939, 1.35639566],\n",
       "       [0.52012165, 0.87264817]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57614482,  1.81609126, -0.053394  ,  1.39354648],\n",
       "       [ 1.27897238,  2.20793743,  2.17670132,  0.08165678]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD \n",
    "- link https://github.com/albertauyeung/matrix-factorization-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mf import MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; error = 1.2474\n",
      "Iteration: 20 ; error = 0.6504\n",
      "Iteration: 30 ; error = 0.3856\n",
      "Iteration: 40 ; error = 0.2755\n",
      "Iteration: 50 ; error = 0.2191\n",
      "Iteration: 60 ; error = 0.1838\n",
      "Iteration: 70 ; error = 0.1598\n",
      "Iteration: 80 ; error = 0.1412\n",
      "Iteration: 90 ; error = 0.1312\n",
      "Iteration: 100 ; error = 0.1197\n",
      "Iteration: 110 ; error = 0.1128\n",
      "Iteration: 120 ; error = 0.1070\n",
      "Iteration: 130 ; error = 0.1019\n",
      "Iteration: 140 ; error = 0.0997\n",
      "Iteration: 150 ; error = 0.0970\n",
      "Iteration: 160 ; error = 0.0931\n",
      "Iteration: 170 ; error = 0.0905\n",
      "Iteration: 180 ; error = 0.0890\n",
      "Iteration: 190 ; error = 0.0875\n",
      "Iteration: 200 ; error = 0.0863\n",
      "Iteration: 210 ; error = 0.0864\n",
      "Iteration: 220 ; error = 0.0827\n",
      "Iteration: 230 ; error = 0.0842\n",
      "Iteration: 240 ; error = 0.0825\n",
      "Iteration: 250 ; error = 0.0832\n",
      "Iteration: 260 ; error = 0.0811\n",
      "Iteration: 270 ; error = 0.0808\n",
      "Iteration: 280 ; error = 0.0800\n",
      "Iteration: 290 ; error = 0.0790\n",
      "Iteration: 300 ; error = 0.0770\n",
      "Iteration: 310 ; error = 0.0785\n",
      "Iteration: 320 ; error = 0.0781\n",
      "Iteration: 330 ; error = 0.0771\n",
      "Iteration: 340 ; error = 0.0752\n",
      "Iteration: 350 ; error = 0.0753\n",
      "Iteration: 360 ; error = 0.0754\n",
      "Iteration: 370 ; error = 0.0757\n",
      "Iteration: 380 ; error = 0.0738\n",
      "Iteration: 390 ; error = 0.0744\n",
      "Iteration: 400 ; error = 0.0743\n",
      "Iteration: 410 ; error = 0.0731\n",
      "Iteration: 420 ; error = 0.0749\n",
      "Iteration: 430 ; error = 0.0736\n",
      "Iteration: 440 ; error = 0.0737\n",
      "Iteration: 450 ; error = 0.0717\n",
      "Iteration: 460 ; error = 0.0708\n",
      "Iteration: 470 ; error = 0.0714\n",
      "Iteration: 480 ; error = 0.0724\n",
      "Iteration: 490 ; error = 0.0716\n",
      "Iteration: 500 ; error = 0.0700\n",
      "Iteration: 510 ; error = 0.0696\n",
      "Iteration: 520 ; error = 0.0708\n",
      "Iteration: 530 ; error = 0.0705\n",
      "Iteration: 540 ; error = 0.0711\n",
      "Iteration: 550 ; error = 0.0705\n",
      "Iteration: 560 ; error = 0.0713\n",
      "Iteration: 570 ; error = 0.0698\n",
      "Iteration: 580 ; error = 0.0691\n",
      "Iteration: 590 ; error = 0.0692\n",
      "Iteration: 600 ; error = 0.0694\n",
      "Iteration: 610 ; error = 0.0682\n",
      "Iteration: 620 ; error = 0.0665\n",
      "Iteration: 630 ; error = 0.0660\n",
      "Iteration: 640 ; error = 0.0694\n",
      "Iteration: 650 ; error = 0.0685\n",
      "Iteration: 660 ; error = 0.0675\n",
      "Iteration: 670 ; error = 0.0684\n",
      "Iteration: 680 ; error = 0.0679\n",
      "Iteration: 690 ; error = 0.0665\n",
      "Iteration: 700 ; error = 0.0677\n",
      "Iteration: 710 ; error = 0.0660\n",
      "Iteration: 720 ; error = 0.0666\n",
      "Iteration: 730 ; error = 0.0647\n",
      "Iteration: 740 ; error = 0.0664\n",
      "Iteration: 750 ; error = 0.0652\n",
      "Iteration: 760 ; error = 0.0662\n",
      "Iteration: 770 ; error = 0.0665\n",
      "Iteration: 780 ; error = 0.0659\n",
      "Iteration: 790 ; error = 0.0646\n",
      "Iteration: 800 ; error = 0.0670\n",
      "Iteration: 810 ; error = 0.0649\n",
      "Iteration: 820 ; error = 0.0648\n",
      "Iteration: 830 ; error = 0.0653\n",
      "Iteration: 840 ; error = 0.0666\n",
      "Iteration: 850 ; error = 0.0649\n",
      "Iteration: 860 ; error = 0.0657\n",
      "Iteration: 870 ; error = 0.0645\n",
      "Iteration: 880 ; error = 0.0637\n",
      "Iteration: 890 ; error = 0.0644\n",
      "Iteration: 900 ; error = 0.0635\n",
      "Iteration: 910 ; error = 0.0633\n",
      "Iteration: 920 ; error = 0.0642\n",
      "Iteration: 930 ; error = 0.0650\n",
      "Iteration: 940 ; error = 0.0637\n",
      "Iteration: 950 ; error = 0.0659\n",
      "Iteration: 960 ; error = 0.0638\n",
      "Iteration: 970 ; error = 0.0642\n",
      "Iteration: 980 ; error = 0.0629\n",
      "Iteration: 990 ; error = 0.0636\n",
      "Iteration: 1000 ; error = 0.0634\n"
     ]
    }
   ],
   "source": [
    "# Perform training and obtain the user and item matrices \n",
    "mf = MF(R, K=2, alpha=0.1, beta=0.01, iterations=1000)\n",
    "training_process = mf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00086709, 4.97812452, 1.0209364 , 2.99645186],\n",
       "       [3.98275957, 3.28553054, 3.78952139, 1.0111819 ],\n",
       "       [2.20092685, 3.99633193, 2.00315468, 1.65198914],\n",
       "       [2.00501115, 3.97274427, 2.99185871, 1.022205  ],\n",
       "       [1.0213927 , 3.00906131, 1.99217613, 0.06609643]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.full_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.20886133,  0.56993655],\n",
       "       [ 0.71483615, -1.13803609],\n",
       "       [-0.20410656,  0.13383063],\n",
       "       [ 0.59682098,  0.47535563],\n",
       "       [ 0.5777785 ,  0.48209749]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.92998677,  0.52378772, -0.4001607 ,  0.6060199 ],\n",
       "       [ 0.33258867,  0.40165206, -0.99406305,  0.92585185]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.Q.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
